{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naomi Osaka & Serena Williams Tweet Database\n",
    "\n",
    "I'd like to build a database with four tables:\n",
    "\n",
    "* Table 1: Naomi Osaka tweets in English\n",
    "    - *search query: \"naomi osaka\"*\n",
    "* Table 2: Naomi Osaka tweets in Japanese\n",
    "    - *search query: \"大阪なおみ\"*\n",
    "* Table 3: Serena Williams tweets in English\n",
    "    - *search query: \"serena williams\"*\n",
    "* Table 4: Serena Williams tweets in Japanese\n",
    "    - *search query: \"セレナウィリアムズ\"*\n",
    "    \n",
    "For each table, I'll collect the following fields:\n",
    "\n",
    "* tweet ID (primary key)\n",
    "* tweet text\n",
    "* tweet loc\n",
    "\n",
    "In this notebook, I will build and maintain these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required dependencies\n",
    "import sys\n",
    "sys.path.append(\"GetOldTweets-python-master/\")\n",
    "import got3\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or connect to database\n",
    "connect = sqlite3.connect('naomi_serena.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables\n",
    "\n",
    "Since the tweets are static objects that already exist, I don't need to worry about saving the tweets as soon as I get them. I can access the same tweets at any time by scraping them from Twitter. I know this from my previous Twitter project. So, I'll be re-creating this database until it looks the way I want it to. Then I'll save it in the final format needed for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Don't want to run this anymore! Tables have been created.\n",
    "# # create or re-create tables\n",
    "# cursor = connect.cursor()\n",
    "\n",
    "# cursor.executescript('''\n",
    "#     DROP TABLE IF EXISTS Naomi_Eng;\n",
    "#     DROP TABLE IF EXISTS Naomi_JP;\n",
    "#     DROP TABLE IF EXISTS Serena_Eng;\n",
    "#     DROP TABLE IF EXISTS Serena_JP;\n",
    "\n",
    "# CREATE TABLE Naomi_Eng (\n",
    "#     id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "#     tweet_id INTEGER,\n",
    "#     tweet_date TEXT,\n",
    "#     tweet_text TEXT,\n",
    "#     tweet_loc TEXT);\n",
    "    \n",
    "# CREATE TABLE Naomi_JP (\n",
    "#     id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "#     tweet_id INTEGER,\n",
    "#     tweet_date TEXT,\n",
    "#     tweet_text TEXT,\n",
    "#     tweet_loc TEXT);\n",
    "    \n",
    "# CREATE TABLE Serena_Eng (\n",
    "#     id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "#     tweet_id INTEGER,\n",
    "#     tweet_date TEXT,\n",
    "#     tweet_text TEXT,\n",
    "#     tweet_loc TEXT);\n",
    "    \n",
    "# CREATE TABLE Serena_JP (\n",
    "#     id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "#     tweet_id INTEGER,\n",
    "#     tweet_date TEXT,\n",
    "#     tweet_text TEXT,\n",
    "#     tweet_loc TEXT);\n",
    "# ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Tables\n",
    "\n",
    "Now that the tables are created with the fields I need, it's time to fill them with some tweets.\n",
    "\n",
    "To start, I'll fill Naomi's English table with 100 tweets.\n",
    "\n",
    "Since her US Open match was on Saturday, September 8, I'll collect only tweets starting on that day and up to 6 days after that day, for about 7 days of tweets.\n",
    "\n",
    "As I mentioned in my preliminary database analysis, the \"naomi osaka\" search query collects all instances of *naomi osaka* including hashtags and capitalized terms, so that will be my official search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # establish tweet criteria\n",
    "\n",
    "# query = \"serena williams\"\n",
    "# start = \"2018-09-08\"\n",
    "# end = \"2018-09-09\"\n",
    "\n",
    "# tweetCriteria = got3.manager.TweetCriteria().setQuerySearch(query).setSince(start).setUntil(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Check\n",
    "\n",
    "First, let's run the package on its own and see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# print(\"Start: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))\n",
    "# print(\"Working...\")\n",
    "# tweet_info = got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "# print(\"Complete.\")\n",
    "# print(\"End: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_info[0]\n",
    "\n",
    "# def printTweet(descr, t):\n",
    "#     print(descr)\n",
    "#     print(\"Username: %s\" % t.username)\n",
    "#     print(\"Retweets: %d\" % t.retweets)\n",
    "#     print(\"Text: %s\" % t.text)\n",
    "#     print(\"Mentions: %s\" % t.mentions)\n",
    "#     print(\"Hashtags: %s\\n\" % t.hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in tweet_info:\n",
    "#     printTweet(\"Test\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finally got the tweets to print, but it was a bit of a struggle trying to figure out how to use the package. I couldn't figure out how to call printTweet directly, so I had to define it in this page. It's really disappointing. I don't know if it's because I don't know how to use this package very well, or because it's not setup very effectively.\n",
    "\n",
    "Regardless, I'm sure I'll be pulling Tweets like this in the future, so it would be nice to have a streamlined package that works how I need it to regardless.\n",
    "\n",
    "But for now, let's just see if I can write these tweets to the database.\n",
    "\n",
    "### ETA:\n",
    "It worked! We're good to go.\n",
    "\n",
    "Since the `got` module is working specifically for this database, I won't mind modifying the code to fit what I'll need for this job. So I'll re-work it to where I'm only grabbing the necessary tweet criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1: \"naomi osaka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set criteria\n",
    "# query = \"naomi osaka\"\n",
    "# start = \"2018-09-08\"\n",
    "# end = \"2018-09-09\"\n",
    "\n",
    "# naomi_eng_tweetCriteria = got3.manager.TweetCriteria().setQuerySearch(query).setSince(start).setUntil(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to Table 1 in DB\n",
    "# got3.manager.TweetManager.getTweets(naomi_eng_tweetCriteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I had to interrupt the data collection because it was STILL GOING after 20 or so minutes.\n",
    "\n",
    "Still, it was much faster than the last time I did this, since I commented out all the code I didn't need!\n",
    "\n",
    "I'm going to go back reassess how many tweets I want to collect and exactly when I want to get them from. I think I can suffice with just getting tweets for the 8th and 9th of September. While people are still talking about this issue today, I think that focusing on the two days when it was most trending would be a good start.\n",
    "\n",
    "I also need to seriously think about capping the number of tweets I collect. Plus, there are bound to be lots of duplicates that I'll need to take care of as well. Lots to consider.\n",
    "\n",
    "Let's do another experiment and see how long it takes to collect all tweets between 9/8/18 and 9/9/18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# print(\"Start: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))\n",
    "# print(\"Working...\")\n",
    "\n",
    "# # writing to Table 1 in Naomi_Serena.db\n",
    "# got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# print(\"Complete.\")\n",
    "# print(\"End: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment was... I'm not sure? Lol I'm not getting the tweet datetime info, so I honestly don't know if I'm getting them all from the right date.\n",
    "\n",
    "Regardless, I know I'm going to have to have a cut-off range at which I stop collecting tweets.\n",
    "\n",
    "So I'll figure that out. I'm thinking 10,000. Even so, I'll have to remove duplicates and get rid of non-English language tweets. Do I keep going then until I have 10,000 perfect, ready-to-use English tweets? Or do I just scrape 10k tweets, clean up the database and work with what I've got?\n",
    "\n",
    "Lot's to consider! That's all for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### September 21, 2018\n",
    "I went ahead and used the `count` variable in TweetManager.py to limit the amount of tweets to 15,000. Even then, I barely got an hour and a half of the tweets that went out with \"naomi osaka\" in them.\n",
    "\n",
    "I'm sure there will be tons more tweets for \"serena williams.\" So my goal is to collect 15,000 tweets there, too.\n",
    "\n",
    "I'm not sure how many Japanese people were tweeting about this, but I'll leave the numbers the same just to be even.\n",
    "\n",
    "So the initial database will have a total of 60,000 tweets. It took about 30 minutes to collect 15,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!! change search term and table to populate in TweetManager.py\n",
    "# query = \"セレナウィリアムズ\"\n",
    "# start = \"2018-09-08\"\n",
    "# end = \"2018-09-10\"\n",
    "\n",
    "# tweetCriteria = got3.manager.TweetCriteria().setQuerySearch(query).setSince(start).setUntil(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  2018/09/22 20:27:12\n",
      "Working...\n",
      "Please enter database name: naomi_serena.db\n",
      "Complete.\n",
      "End:  2018/09/22 20:27:31\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "# print(\"Start: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))\n",
    "# print(\"Working...\")\n",
    "# tweet_info = got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "# print(\"Complete.\")\n",
    "# print(\"End: \", datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm almost done collecting my database. I was shocked to see that I only collected 30 tweets for the query \"セレナウイリアムズ\"! I forgot to correct for time zone. So I ended the valid date before Japan was even awake to be able to tweet about all this.\n",
    "\n",
    "So I extended the end date to \"2018-09-10\" for the Japanese tweets hoping to get up to that same 15k figure.\n",
    "\n",
    "But even after extending the start date, I only managed to collect 114 tweets, as opposed to the near 5k I collected for Naomi Osaka. It seems like Serena Williams just isn't talked about in Japan. Perhaps this issue isn't as public as it in in the English-speaking world?\n",
    "\n",
    "Regardless, I'll continue my analysis with the set database that I have. I'll focus on my English tweets first, and then we'll see what we can do with the Japanese ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Database\n",
    "\n",
    "In the previous notebook, I played around with the GetOldTweets python package I'd downloaded and pulled some tweets with the search criteria I was interested in.\n",
    "\n",
    "Now it's time to start creating the database that will hold these tweets.\n",
    "\n",
    "Thinking back on the last project I did, I gathered way too much information. I collected nearly 100k tweets, with identifying information such as the tweet ID, geo location, time stamps and others.\n",
    "\n",
    "But for this project, I want to run a sentiment analysis, and I want to keep it pretty simple. At the bare minimum, I'm only going to need the tweet text. I could collect the hashtags, but from the preliminary data analysis the search criteria will grab whole words (\"Naomi Osaka\") as well as hashtags (\"#naomiosaka\") so I don't need to duplicate this information.\n",
    "\n",
    "I would, though, at least like to gather location information (if available) so I can see if the sentiment towards Naomi and Serena differs depending on where in the world the person is Tweeting from.\n",
    "\n",
    "In that same vein, I'll be pulling Japanese-only tweets into separate tables, and hoping to find a way to filter out non-English tweets from the English tables.\n",
    "\n",
    "So, it looks like I will have a database of \"Naomi Serena Tweets\" with the following tables, delineated by search query:\n",
    "\n",
    "* \"naomi osaka\"\n",
    "* \"serena williams\"\n",
    "* \"大阪なおみ\"\n",
    "* \"セレナウィリアムズ\"\n",
    "\n",
    "For each table, I'll need to populate it with the following information:\n",
    "\n",
    "* tweetID\n",
    "* tweet text\n",
    "* tweet location\n",
    "\n",
    "That will give me a unique ID to identify each tweet by, the main text of the tweet that I want to analyze, and the possible location of each tweet for further analysis.\n",
    "\n",
    "## Environment Setup\n",
    "So that this project can be run entirely in Jupyter, I'm going to move my copy of GetOldTweets into this directory so I can call it without constantly appending it to the syspath. I'll also import the database management module I'm going to be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"GetOldTweets-python-master/\")\n",
    "import got3\n",
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DB\n",
    "Before I create the real thing, I want to make sure I know how to use the module. So I'll be creating and populating test tables here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "connect = sqlite3.connect('test.db')\n",
    "print(sqlite3.version)\n",
    "connect.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That successfully created a database titled \"test\" in the current directory. Now I'll try to populate it with a few tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22cffcf95e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect = sqlite3.connect('test.db')\n",
    "cursor = connect.cursor()\n",
    "\n",
    "cursor.executescript('''\n",
    "    DROP TABLE IF EXISTS Test001;\n",
    "    DROP TABLE IF EXISTS Test002;\n",
    "\n",
    "CREATE TABLE Test001 (\n",
    "    id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    tweet_id INTEGER,\n",
    "    tweet_text TEXT,\n",
    "    tweet_loc TEXT);\n",
    "    \n",
    "CREATE TABLE Test002 (\n",
    "    id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    tweet_id INTEGER,\n",
    "    tweet_text TEXT,\n",
    "    tweet_loc TEXT);\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0x0000022CFFCF95E0>\n"
     ]
    }
   ],
   "source": [
    "print(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! That wasn't too bad.\n",
    "\n",
    "Okay. I think I'm ready to build my databases and start populating them. I'll be doing this in a separate notebook to keep everything neat and tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
